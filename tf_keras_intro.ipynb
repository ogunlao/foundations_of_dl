{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.0', '2.2.4-tf')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_test.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights for layer 1: (784, 300)\n",
      "bias for layer 1: (300,)\n"
     ]
    }
   ],
   "source": [
    "print(\"weights for layer 1:\", model.get_weights()[0].shape)\n",
    "print(\"bias for layer 1:\", model.get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.7047 - accuracy: 0.7717 - val_loss: 0.5027 - val_accuracy: 0.8240\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.4823 - accuracy: 0.8325 - val_loss: 0.4787 - val_accuracy: 0.8282\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.4396 - accuracy: 0.8465 - val_loss: 0.4147 - val_accuracy: 0.8594\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4121 - accuracy: 0.8554 - val_loss: 0.3877 - val_accuracy: 0.8672\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3927 - accuracy: 0.8635 - val_loss: 0.3773 - val_accuracy: 0.8702\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.3761 - accuracy: 0.8686 - val_loss: 0.3706 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3636 - accuracy: 0.8726 - val_loss: 0.3585 - val_accuracy: 0.8746\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3524 - accuracy: 0.8751 - val_loss: 0.3655 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3412 - accuracy: 0.8794 - val_loss: 0.3612 - val_accuracy: 0.8770\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3329 - accuracy: 0.8817 - val_loss: 0.3377 - val_accuracy: 0.8818\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.3243 - accuracy: 0.8845 - val_loss: 0.3488 - val_accuracy: 0.8788\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.3160 - accuracy: 0.8872 - val_loss: 0.3353 - val_accuracy: 0.8852\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.3093 - accuracy: 0.8901 - val_loss: 0.3258 - val_accuracy: 0.8862\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3023 - accuracy: 0.8917 - val_loss: 0.3234 - val_accuracy: 0.8870\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2958 - accuracy: 0.8941 - val_loss: 0.3184 - val_accuracy: 0.8900\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2901 - accuracy: 0.8955 - val_loss: 0.3231 - val_accuracy: 0.8844\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2834 - accuracy: 0.8970 - val_loss: 0.3097 - val_accuracy: 0.8882\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2780 - accuracy: 0.8990 - val_loss: 0.3133 - val_accuracy: 0.8884\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2739 - accuracy: 0.9019 - val_loss: 0.3061 - val_accuracy: 0.8882\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2688 - accuracy: 0.9038 - val_loss: 0.3078 - val_accuracy: 0.8892\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2627 - accuracy: 0.9058 - val_loss: 0.3296 - val_accuracy: 0.8844\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2582 - accuracy: 0.9068 - val_loss: 0.3000 - val_accuracy: 0.8904\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2544 - accuracy: 0.9073 - val_loss: 0.3019 - val_accuracy: 0.8878\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2487 - accuracy: 0.9102 - val_loss: 0.3148 - val_accuracy: 0.8860\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2454 - accuracy: 0.9115 - val_loss: 0.2995 - val_accuracy: 0.8906\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2408 - accuracy: 0.9134 - val_loss: 0.3012 - val_accuracy: 0.8932\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2368 - accuracy: 0.9144 - val_loss: 0.3043 - val_accuracy: 0.8922\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2330 - accuracy: 0.9162 - val_loss: 0.3130 - val_accuracy: 0.8870\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2292 - accuracy: 0.9177 - val_loss: 0.2960 - val_accuracy: 0.8978\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2247 - accuracy: 0.9195 - val_loss: 0.3004 - val_accuracy: 0.8924\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save .h5 model and parameters\n",
    "model.save(\"model0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability of each class\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(1)])\n",
    "model1.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(X_train_scaled, y_train, epochs=20, \n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = model1.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model1.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model2 = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model3 = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid_scaled[:, :5], X_valid_scaled[:, 2:]\n",
    "X_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit((X_train_A, X_train_B), y_train, epochs=20, \n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = model3.evaluate((X_test_A, X_test_B), y_test, verbose=0)\n",
    "y_pred = model3.predict((X_new_A, X_new_B))\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "model4 = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model4.fit((X_train_A, X_train_B), y_train, epochs=20, \n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # Define your layers here.\n",
    "        self.dense_1 = keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = keras.layers.Dense(num_classes, activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # You need to override this function if you want to use the subclassed model\n",
    "        # as part of a functional-style model.\n",
    "        # Otherwise, this method is optional.\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "\n",
    "# Instantiates the subclassed model.\n",
    "model5 = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model5.compile(keras.optimizers.RMSprop(0.001),\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "data = X_train_scaled; labels=y_train\n",
    "# Trains for 5 epochs.\n",
    "model5.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "keras_reg.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_valid_scaled, y_valid), \n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)], verbose=0)\n",
    "\n",
    "mse_test = keras_reg.score(X_test_scaled, y_test, verbose=0) #Keras implementation of evaluate\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "                    \"n_hidden\": [0, 1, 2, 3],\n",
    "                    \"n_neurons\": np.arange(1, 100),\n",
    "                    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "                    }\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=3, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train, epochs=10, \n",
    "                  validation_data=(X_valid_scaled, y_valid), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=169903, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=169904, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(t.shape, t.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "# Load sample images\n",
    "china = load_sample_image(\"china.jpg\") / 255\n",
    "flower = load_sample_image(\"flower.jpg\") / 255\n",
    "images = np.array([china, flower])\n",
    "batch_size, height, width, channels = images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "    kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "    model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102973440/102967424 [==============================] - 66s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-50 requires input of size 224 X 224\n",
    "images_resized = tf.image.resize(images, [224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PReprocessing for ResNet\n",
    "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #0\n",
      " n02825657 - bell_cote    82.35%\n",
      " n03877845 - palace       6.75%\n",
      " n03781244 - monastery    4.19%\n",
      " n02980441 - castle       3.16%\n",
      " n03028079 - church       1.00%\n",
      "\n",
      "Image #1\n",
      " n03530642 - honeycomb    49.81%\n",
      " n13040303 - stinkhorn    33.96%\n",
      " n02206856 - bee          4.35%\n",
      " n11939491 - daisy        3.23%\n",
      " n12985857 - coral_fungus 2.66%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=5)\n",
    "for image_index in range(len(images)):\n",
    "    print(\"Image #{}\".format(image_index))\n",
    "    for class_id, name, y_proba in top_K[image_index]:\n",
    "        print(\" {} - {:12s} {:.2f}%\".format(class_id, name, y_proba * 100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinarySearch(arr, val):\n",
    "    first = 0\n",
    "    last = len(arr) - 1\n",
    "    mid = (first + last)//2\n",
    "    \n",
    "    if last < first: return -1\n",
    "    elif arr[mid] < val:\n",
    "        #first = mid+1\n",
    "        return BinarySearch(arr[mid+1:last+1], val)\n",
    "    elif arr[mid] > val: \n",
    "        #last = mid - 1\n",
    "        return BinarySearch(arr[first:mid], val)\n",
    "    else:\n",
    "        if arr[mid] == val: return 1\n",
    "        \n",
    "result = BinarySearch(arr[first:mid], val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(BinarySearch([1,2,3,4,5], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Program for recursive binary search. \n",
    "\n",
    "# Returns index of x in arr if present, else -1 \n",
    "def binarySearch (arr, l, r, x): \n",
    "\n",
    "\t# Check base case \n",
    "\tif r >= l: \n",
    "\n",
    "\t\tmid = l + (r - l)//2\n",
    "\n",
    "\t\t# If element is present at the middle itself \n",
    "\t\tif arr[mid] == x: \n",
    "\t\t\treturn mid \n",
    "\t\t\n",
    "\t\t# If element is smaller than mid, then it \n",
    "\t\t# can only be present in left subarray \n",
    "\t\telif arr[mid] > x: \n",
    "\t\t\treturn binarySearch(arr, l, mid-1, x) \n",
    "\n",
    "\t\t# Else the element can only be present \n",
    "\t\t# in right subarray \n",
    "\t\telse: \n",
    "\t\t\treturn binarySearch(arr, mid + 1, r, x) \n",
    "\n",
    "\telse: \n",
    "\t\t# Element is not present in the array \n",
    "\t\treturn -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).reshape(5,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(a).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
